{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9afe6e68-24d5-41f7-ab01-70ead3fb0179",
   "metadata": {},
   "source": [
    "## K-means Clustering Algorithm\n",
    "The [K-means algorithm](https://en.wikipedia.org/wiki/K-means_clustering), originally developed by [Lloyd in the 1950s but not published until much later in 1982](https://ieeexplore.ieee.org/document/1056489), is our first example of $\\texttt{unsupervised learning}$. Suppose we have a dataset $\\mathcal{D}=\\left\\{\\mathbf{x}_{1},\\mathbf{x}_{2},\\dots,\\mathbf{x}_{n}\\in\\mathbb{R}^{m}\\right\\}$ where each $\\mathbf{x}\\in\\mathbb{R}^{m}$ is an $m$-dimensional feature vector.\n",
    "[K-means](https://en.wikipedia.org/wiki/K-means_clustering) is a popular unsupervised machine learning algorithm for clustering data points (feature vectors) $\\mathbf{x}\\in\\mathcal{D}$ into distinct a set of groups (clusters) $\\mathcal{C} = \\left\\{\\mathcal{c}_{1},\\dots,\\mathcal{c}_{K}\\right\\}$ based on _similarity_.\n",
    "\n",
    "* __Similarity__ refers to how _close_ data points are to each other in the feature space, i.e., how close $\\mathbf{x}_{i}$ is to $\\mathbf{x}_{j}$ using a distance of similarity measure $d(\\mathbf{x},\\mathbf{y})$. _Close features are assumed to be similar_. The most commonly used similarity measure in [K-means clustering](https://en.wikipedia.org/wiki/K-means_clustering) is [Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance). However, we can use other types of measures. The choice of similarity measure can significantly impact the resulting clusters.\n",
    "\n",
    "__Algorithm__\n",
    "* __Initialization__. You give the data set $\\mathbf{x}\\in\\mathcal{D}$, which contains `n` data vectors (measurements, observations, etc) $\\mathbf{x}_{1},\\dots,\\mathbf{x}_{n}$ where each vector $\\mathbf{x}_{i}$ has `m` features, and the number and (initial) locations of K-clusters to the algorithm. Each cluster $\\mathcal{c}_{k}$ is represented by a $\\texttt{centroid}$, i.e., the mean of the set of data points in the cluster $\\left\\{\\mathbf{x}_{i}\\right\\}_{i\\in\\mathcal{c}_{k}}$. In the [K-means approach](https://en.wikipedia.org/wiki/K-means_clustering), you have to tell the algorithm how many clusters and the initial location of each cluster. This initial guess is then iteratively refined.\n",
    "* __Iterative Update__. The [K-means algorithm](https://en.wikipedia.org/wiki/K-means_clustering) employs an iterative process in which data points are assigned to the nearest cluster centroid, and the centroids are subsequently updated based on the mean of the assigned points. This process continues until a predetermined stopping criterion is satisfied.\n",
    "* __Stopping__. There are several ways the [K-means algorithm](https://en.wikipedia.org/wiki/K-means_clustering) can terminate. The stopping criteria for the [K-means clustering algorithm](https://en.wikipedia.org/wiki/K-means_clustering) include when the cluster centroids do not change significantly, when data points remain in the same clusters across iterations, or when a maximum number of iterations is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45657f9b-b35c-4d22-a03e-a055e245c2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
